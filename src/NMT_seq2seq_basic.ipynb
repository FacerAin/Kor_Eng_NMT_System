{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python37464bitvenvvenv1c8fbc684c88465593970c8fb2f22879",
      "display_name": "Python 3.7.4 64-bit ('venv': venv)"
    },
    "colab": {
      "name": "NMT_seq2seq_basic.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5hhSZna0zh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "849b4e4a-6f47-47a6-8179-6cecb552b2ae"
      },
      "source": [
        "#For Colab ENV\n",
        "from google.colab import drive \n",
        "drive.mount('/gdrive')\n",
        "!git clone https://github.com/FacerAin/Kor_Eng_NMT_System.git '/gdrive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "Cloning into '/gdrive/My Drive/Colab Notebooks'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 18 (delta 2), reused 8 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dpGBb-X0d68",
        "colab_type": "text"
      },
      "source": [
        "## NMT_seq2seq_basic\n",
        "\n",
        "Character Level NMT based on Simple Seq2Seq Model Without Attention Mechanism \n",
        "\n",
        "Refer to https://github.com/keras-team/keras/blob/master/examples/lstm_seq2seq.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V27ojmrJ0d6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaIyZgSr0d7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameter Setting\n",
        "dataset_dir_path = '/gdrive/My Drive/Colab Notebooks//dataset/kor-eng/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsfBWDMn0d7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Text data\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "d7BvUjss0d7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read Dataset and Preprocessing\n",
        "with open(dataset_dir_path+\"kor.txt\", \"r\", encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "    for line in lines[:len(lines)-2]:#To Except Last Line\n",
        "        split_line = line.split('\\t')\n",
        "        input_text = split_line[0]\n",
        "        target_text = '^' + split_line[1]+ '&' #Using '^' to start tag, '&' to end tag\n",
        "        input_texts.append(input_text)\n",
        "        target_texts.append(target_text)\n",
        "        for char_item in input_text:\n",
        "            input_characters.add(char_item)\n",
        "        for char_item in target_text:\n",
        "            target_characters.add(char_item)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OutOaTNo0d7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_characters = sorted(input_characters)\n",
        "target_characters = sorted(target_characters)\n",
        "\n",
        "encoder_token_num = len(input_characters)\n",
        "target_token_num = len(target_characters)\n",
        "\n",
        "max_encoder_seq_length = max([len(item) for item in input_texts])\n",
        "max_decoder_seq_length = max([len(item) for item in target_texts])\n",
        "\n",
        "encoder_token_index_dict = dict([(char_item, i) for i, char_item in enumerate(input_characters)])\n",
        "target_token_index_dict = dict([(char_item, i) for i, char_item in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, encoder_token_num), dtype='float32')\n",
        "decoder_input_data = np.zeros((len(target_texts), max_decoder_seq_length, target_token_num), dtype='float32')\n",
        "decoder_target_data = np.zeros((len(target_texts), max_decoder_seq_length, target_token_num), dtype='float32')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "5Y0rJKos0d7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,(input_text, target_text) in enumerate(zip(input_texts,target_texts)):\n",
        "    for j, char_item in enumerate(input_text):\n",
        "        encoder_input_data[i, j, encoder_token_index_dict[char_item]] = 1.\n",
        "    encoder_input_data[i, j+1:, encoder_token_index_dict[\" \"]] = 1.\n",
        "    for j, char_item in enumerate(target_text):\n",
        "        decoder_input_data[i, j, target_token_index_dict[char_item]] = 1.\n",
        "        if j > 0:\n",
        "            decoder_target_data[i , j-1, target_token_index_dict[char_item]] = 1.\n",
        "        decoder_input_data[i, j+1: ,target_token_index_dict[\" \"]] = 1.\n",
        "        decoder_target_data[i, j:, target_token_index_dict[\" \"]] = 1."
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQgkj_EO0d7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}